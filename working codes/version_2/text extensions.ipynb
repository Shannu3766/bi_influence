{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/working/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:32:42.482063Z","iopub.execute_input":"2025-11-06T19:32:42.482561Z","iopub.status.idle":"2025-11-06T19:32:42.745986Z","shell.execute_reply.started":"2025-11-06T19:32:42.482535Z","shell.execute_reply":"2025-11-06T19:32:42.745394Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# !pip install git+https://github.com/Shannu3766/bi_influence.git\n\n!pip install --upgrade --no-cache-dir git+https://github.com/Shannu3766/bi_influence.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:32:42.747085Z","iopub.execute_input":"2025-11-06T19:32:42.747422Z","iopub.status.idle":"2025-11-06T19:34:03.790845Z","shell.execute_reply.started":"2025-11-06T19:32:42.747394Z","shell.execute_reply":"2025-11-06T19:34:03.790124Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/Shannu3766/bi_influence.git\n  Cloning https://github.com/Shannu3766/bi_influence.git to /tmp/pip-req-build-myk_ma90\n  Running command git clone --filter=blob:none --quiet https://github.com/Shannu3766/bi_influence.git /tmp/pip-req-build-myk_ma90\n  Resolved https://github.com/Shannu3766/bi_influence.git to commit e94452e6f87a2e19e8ebcc30e94fc4dd0d0ff5c3\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (2.6.0+cu124)\nRequirement already satisfied: transformers>=4.30 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (4.53.3)\nRequirement already satisfied: peft>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (0.16.0)\nRequirement already satisfied: datasets>=2.0 in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (4.1.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (4.67.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (1.26.4)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (1.2.2)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (1.9.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from adaptive_lora==2.1.0) (2.2.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (3.19.1)\nCollecting pyarrow>=21.0.0 (from datasets>=2.0->adaptive_lora==2.1.0)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (0.4.0)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (2.32.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (0.70.16)\nRequirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (2025.9.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (1.0.0rc2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0->adaptive_lora==2.1.0) (6.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->adaptive_lora==2.1.0) (2.4.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft>=0.3.0->adaptive_lora==2.1.0) (7.1.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft>=0.3.0->adaptive_lora==2.1.0) (0.5.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13->adaptive_lora==2.1.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->adaptive_lora==2.1.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->adaptive_lora==2.1.0) (1.3.0)\nCollecting huggingface-hub>=0.24.0 (from datasets>=2.0->adaptive_lora==2.1.0)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30->adaptive_lora==2.1.0) (2025.9.18)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.30->adaptive_lora==2.1.0) (0.21.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->adaptive_lora==2.1.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->adaptive_lora==2.1.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->adaptive_lora==2.1.0) (2025.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->adaptive_lora==2.1.0) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->adaptive_lora==2.1.0) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->adaptive_lora==2.1.0) (3.6.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (3.12.15)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets>=2.0->adaptive_lora==2.1.0) (1.1.10)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->adaptive_lora==2.1.0) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0->adaptive_lora==2.1.0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0->adaptive_lora==2.1.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0->adaptive_lora==2.1.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.0->adaptive_lora==2.1.0) (2025.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->adaptive_lora==2.1.0) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->adaptive_lora==2.1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->adaptive_lora==2.1.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->adaptive_lora==2.1.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->adaptive_lora==2.1.0) (2024.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=2.0->adaptive_lora==2.1.0) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->adaptive_lora==2.1.0) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m203.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: adaptive_lora\n  Building wheel for adaptive_lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for adaptive_lora: filename=adaptive_lora-2.1.0-py3-none-any.whl size=8954 sha256=a13fe0b678f2a42b6d57e61491d38fc2860fd613a8df8915bcd75886258ae197\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ch1ii6sc/wheels/4b/91/1d/e153ff3aa3759d6ccdcc4706d8559f1cbfaa4aa22b992958cd\nSuccessfully built adaptive_lora\nInstalling collected packages: pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12, adaptive_lora\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed adaptive_lora-2.1.0 huggingface-hub-0.36.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install -q datasets evaluate accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:03.791762Z","iopub.execute_input":"2025-11-06T19:34:03.792041Z","iopub.status.idle":"2025-11-06T19:34:07.507405Z","shell.execute_reply.started":"2025-11-06T19:34:03.792018Z","shell.execute_reply":"2025-11-06T19:34:07.506108Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -U datasets==2.20.0 pyarrow==15.0.2 transformers==4.44.2 evaluate==0.4.2 --no-cache-dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:07.509828Z","iopub.execute_input":"2025-11-06T19:34:07.510051Z","iopub.status.idle":"2025-11-06T19:34:24.426305Z","shell.execute_reply.started":"2025-11-06T19:34:07.510025Z","shell.execute_reply":"2025-11-06T19:34:24.425357Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting datasets==2.20.0\n  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\nCollecting pyarrow==15.0.2\n  Downloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nCollecting transformers==4.44.2\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting evaluate==0.4.2\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.19.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (1.26.4)\nCollecting pyarrow-hotfix (from datasets==2.20.0)\n  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\nCollecting dill<0.3.9,>=0.3.0 (from datasets==2.20.0)\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (2.32.5)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.70.16)\nCollecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0)\n  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (3.12.15)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.20.0) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2025.9.18)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.20.0) (1.20.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.20.0) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2025.8.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.20.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.20.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.20.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets==2.20.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets==2.20.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets==2.20.0) (2024.2.0)\nDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-15.0.2-cp311-cp311-manylinux_2_28_x86_64.whl (38.3 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m192.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m164.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m282.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m309.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m340.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m180.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, dill, tokenizers, pyarrow, datasets, transformers, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.9.0\n    Uninstalling fsspec-2025.9.0:\n      Successfully uninstalled fsspec-2025.9.0\n  Attempting uninstall: dill\n    Found existing installation: dill 0.4.0\n    Uninstalling dill-0.4.0:\n      Successfully uninstalled dill-0.4.0\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 22.0.0\n    Uninstalling pyarrow-22.0.0:\n      Successfully uninstalled pyarrow-22.0.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.1.1\n    Uninstalling datasets-4.1.1:\n      Successfully uninstalled datasets-4.1.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: evaluate\n    Found existing installation: evaluate 0.4.6\n    Uninstalling evaluate-0.4.6:\n      Successfully uninstalled evaluate-0.4.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 evaluate-0.4.2 fsspec-2024.5.0 pyarrow-15.0.2 pyarrow-hotfix-0.7 tokenizers-0.19.1 transformers-4.44.2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# !pip uninstall adaptive_lora -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:24.427498Z","iopub.execute_input":"2025-11-06T19:34:24.427777Z","iopub.status.idle":"2025-11-06T19:34:24.431606Z","shell.execute_reply.started":"2025-11-06T19:34:24.427755Z","shell.execute_reply":"2025-11-06T19:34:24.431066Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# !pip install git+https://github.com/Shannu3766/bi_influence.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:24.432397Z","iopub.execute_input":"2025-11-06T19:34:24.432573Z","iopub.status.idle":"2025-11-06T19:34:24.447381Z","shell.execute_reply.started":"2025-11-06T19:34:24.432558Z","shell.execute_reply":"2025-11-06T19:34:24.446569Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# 泅 Step 1: Install Dependencies and Package\n# ============================================================\n!pip install -q datasets evaluate accelerate scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:24.448020Z","iopub.execute_input":"2025-11-06T19:34:24.448225Z","iopub.status.idle":"2025-11-06T19:34:27.920401Z","shell.execute_reply.started":"2025-11-06T19:34:24.448210Z","shell.execute_reply":"2025-11-06T19:34:27.919352Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# 泅 STEP 1: Install dependencies & your Adaptive LoRA package\n# ============================================================\n!pip install -q datasets evaluate accelerate scikit-learn pandas matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:27.921508Z","iopub.execute_input":"2025-11-06T19:34:27.922416Z","iopub.status.idle":"2025-11-06T19:34:31.516877Z","shell.execute_reply.started":"2025-11-06T19:34:27.922377Z","shell.execute_reply":"2025-11-06T19:34:31.516009Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    Trainer,\n    TrainingArguments,\n)\nfrom datasets import load_dataset, Dataset\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom torch.utils.data import DataLoader\nfrom adaptive_lora.callbacks import AdaptiveLoRACallback\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction  # 笨 FIXED\nimport numpy as np\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:31.517964Z","iopub.execute_input":"2025-11-06T19:34:31.518202Z","iopub.status.idle":"2025-11-06T19:34:53.181494Z","shell.execute_reply.started":"2025-11-06T19:34:31.518179Z","shell.execute_reply":"2025-11-06T19:34:53.180912Z"}},"outputs":[{"name":"stderr","text":"2025-11-06 19:34:38.552621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762457678.749471      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762457678.801621      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.ChunkedArray size changed, may indicate binary incompatibility. Expected 64 from C header, got 72 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib._Tabular size changed, may indicate binary incompatibility. Expected 24 from C header, got 32 from PyObject\n<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Table size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# --- 1. Setup Model and Tokenizer ---","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:53.183517Z","iopub.execute_input":"2025-11-06T19:34:53.184348Z","iopub.status.idle":"2025-11-06T19:34:53.187737Z","shell.execute_reply.started":"2025-11-06T19:34:53.184325Z","shell.execute_reply":"2025-11-06T19:34:53.186904Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model_name = \"mistralai/Mistral-7B-v0.1\" # Example model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name, \n    torch_dtype=torch.bfloat16, # Use bfloat16 for efficiency\n    device_map=\"auto\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:34:53.188580Z","iopub.execute_input":"2025-11-06T19:34:53.188861Z","iopub.status.idle":"2025-11-06T19:37:24.208193Z","shell.execute_reply.started":"2025-11-06T19:34:53.188844Z","shell.execute_reply":"2025-11-06T19:37:24.207569Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f450f93d65a544f2b7e20df0b7ddaeb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d835d9b31b7b4e049203f42ecc2944a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bcc0405620f40cd98706cb3f615da26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aa3d074837944acbaee3a0bfa2e4ced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ac597f48504eeaa19feee63e54f938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e079a51e0954da08392f39e423c98a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03168512e30e4ba09588c34755a91565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9a4454f0a914296b4a8d69a78cbb7bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5779a05410a042368bc6b37fbe3d6bd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b7a37a6dfe84fbc9db7dc96ffcb2124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8834b307303414cb12625fae81c383f"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n    task_type=TaskType.CAUSAL_LM,\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:37:24.208985Z","iopub.execute_input":"2025-11-06T19:37:24.209225Z","iopub.status.idle":"2025-11-06T19:37:27.784679Z","shell.execute_reply.started":"2025-11-06T19:37:24.209207Z","shell.execute_reply":"2025-11-06T19:37:27.783983Z"}},"outputs":[{"name":"stdout","text":"trainable params: 13,631,488 || all params: 7,255,363,584 || trainable%: 0.1879\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n\ntrain_texts = dataset[\"train\"][\"text\"][:50]\nval_texts = dataset[\"validation\"][\"text\"][:20]\ntest_texts = dataset[\"test\"][\"text\"][:10]\n\ndef tokenize_data(texts):\n    enc = tokenizer(\n        texts,\n        truncation=True,\n        padding=\"max_length\",\n        max_length=128,\n        return_tensors=\"pt\"\n    )\n    enc[\"labels\"] = enc[\"input_ids\"].clone()\n    return Dataset.from_dict({k: v.tolist() for k, v in enc.items()})\n\ntrain_dataset = tokenize_data(train_texts)\nval_dataset = tokenize_data(val_texts)\ntest_dataset = tokenize_data(test_texts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:37:27.785700Z","iopub.execute_input":"2025-11-06T19:37:27.785979Z","iopub.status.idle":"2025-11-06T19:37:31.545603Z","shell.execute_reply.started":"2025-11-06T19:37:27.785955Z","shell.execute_reply":"2025-11-06T19:37:31.545033Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fc100510b2e4c3c8f9138752144aa98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28a2da5c4744e5b85684e37f2ee5681"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce21e3eb14542cc85e5bd95b28a3964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26b3ab30efff4f769965c120f295661f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb08642f6c89480a8222893cf11da407"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a86ea4ae2c2f4509824066b83b4b9762"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d075d3fd58fb423dae61d103e2c66d89"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# ============================================================\ndef collate_fn(batch):\n    features = {key: [example[key] for example in batch] for key in batch[0].keys()}\n    padded = tokenizer.pad(\n        features,\n        return_tensors=\"pt\",\n        padding=\"max_length\",\n        max_length=128\n    )\n    return padded\n\nval_loader_for_callback = DataLoader(\n    val_dataset,\n    batch_size=4,\n    collate_fn=collate_fn\n)\n\n\nadaptive_callback = AdaptiveLoRACallback(\n    total_rank=512,\n    tau=0.8,\n    val_dataloader=val_loader_for_callback,\n    verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:37:31.546442Z","iopub.execute_input":"2025-11-06T19:37:31.546692Z","iopub.status.idle":"2025-11-06T19:37:31.551619Z","shell.execute_reply.started":"2025-11-06T19:37:31.546674Z","shell.execute_reply":"2025-11-06T19:37:31.550836Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    \"\"\"\n    Computes BLEU, Perplexity, and Loss 窶 works fully offline.\n    \"\"\"\n    logits, labels = eval_pred\n    logits = torch.tensor(logits)\n    labels = torch.tensor(labels)\n\n    # Compute loss & perplexity\n    shift_logits = logits[..., :-1, :].contiguous()\n    shift_labels = labels[..., 1:].contiguous()\n    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n    perplexity = torch.exp(loss)\n\n    # Decode text\n    preds = torch.argmax(logits, dim=-1)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Compute BLEU score\n    smoothie = SmoothingFunction().method4\n    bleu_scores = [\n        sentence_bleu([ref.split()], pred.split(), smoothing_function=smoothie)\n        for pred, ref in zip(decoded_preds, decoded_labels)\n    ]\n\n    return {\n        \"loss\": loss.item(),\n        \"perplexity\": perplexity.item(),\n        \"bleu\": float(np.mean(bleu_scores))\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:37:31.552454Z","iopub.execute_input":"2025-11-06T19:37:31.552735Z","iopub.status.idle":"2025-11-06T19:37:31.580338Z","shell.execute_reply.started":"2025-11-06T19:37:31.552713Z","shell.execute_reply":"2025-11-06T19:37:31.579580Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=5,\n    report_to=\"none\",\n    save_strategy=\"no\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    callbacks=[adaptive_callback],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:37:31.581171Z","iopub.execute_input":"2025-11-06T19:37:31.581765Z","iopub.status.idle":"2025-11-06T19:37:31.654724Z","shell.execute_reply.started":"2025-11-06T19:37:31.581738Z","shell.execute_reply":"2025-11-06T19:37:31.654028Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 洟 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nStarting training with Adaptive LoRA on WikiText (pre-epoch allocation)...\")\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:37:31.655390Z","iopub.execute_input":"2025-11-06T19:37:31.655585Z","iopub.status.idle":"2025-11-06T19:44:18.523472Z","shell.execute_reply.started":"2025-11-06T19:37:31.655570Z","shell.execute_reply":"2025-11-06T19:44:18.522677Z"}},"outputs":[{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\nWe detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","output_type":"stream"},{"name":"stdout","text":"\nStarting training with Adaptive LoRA on WikiText (pre-epoch allocation)...\n\n--- AdaptiveLoRA: Preparing ranks for Epoch 1 ---\nComputing BI importance scores (pre-training)...\nAllocating new ranks based on BI scores...\nApplying new ranks to LoRA modules for this epoch...\n  - base_model.model.model.layers.0.self_attn.q_proj: r=16 竊 4 (Score: 0.3409)\n  - base_model.model.model.layers.0.self_attn.k_proj: r=16 竊 4 (Score: 0.3332)\n  - base_model.model.model.layers.0.self_attn.v_proj: r=16 竊 5 (Score: 0.4457)\n  - base_model.model.model.layers.0.self_attn.o_proj: r=16 竊 4 (Score: 0.2834)\n  - base_model.model.model.layers.1.self_attn.q_proj: r=16 竊 4 (Score: 0.2290)\n  - base_model.model.model.layers.1.self_attn.k_proj: r=16 竊 3 (Score: 0.0138)\n  - base_model.model.model.layers.1.self_attn.v_proj: r=16 竊 3 (Score: 0.1664)\n  - base_model.model.model.layers.1.self_attn.o_proj: r=16 竊 4 (Score: 0.2309)\n  - base_model.model.model.layers.2.self_attn.q_proj: r=16 竊 4 (Score: 0.3366)\n  - base_model.model.model.layers.2.self_attn.k_proj: r=16 竊 5 (Score: 0.4551)\n  - base_model.model.model.layers.2.self_attn.v_proj: r=16 竊 3 (Score: 0.1450)\n  - base_model.model.model.layers.2.self_attn.o_proj: r=16 竊 4 (Score: 0.3197)\n  - base_model.model.model.layers.3.self_attn.q_proj: r=16 竊 4 (Score: 0.3458)\n  - base_model.model.model.layers.3.self_attn.k_proj: r=16 竊 3 (Score: 0.1457)\n  - base_model.model.model.layers.3.self_attn.v_proj: r=16 竊 3 (Score: 0.1881)\n  - base_model.model.model.layers.3.self_attn.o_proj: r=16 竊 4 (Score: 0.3227)\n  - base_model.model.model.layers.4.self_attn.q_proj: r=16 竊 4 (Score: 0.2139)\n  - base_model.model.model.layers.4.self_attn.k_proj: r=16 竊 4 (Score: 0.3109)\n  - base_model.model.model.layers.4.self_attn.v_proj: r=16 竊 3 (Score: 0.1075)\n  - base_model.model.model.layers.4.self_attn.o_proj: r=16 竊 4 (Score: 0.2285)\n  - base_model.model.model.layers.5.self_attn.q_proj: r=16 竊 4 (Score: 0.2873)\n  - base_model.model.model.layers.5.self_attn.k_proj: r=16 竊 3 (Score: 0.0000)\n  - base_model.model.model.layers.5.self_attn.v_proj: r=16 竊 4 (Score: 0.4014)\n  - base_model.model.model.layers.5.self_attn.o_proj: r=16 竊 5 (Score: 0.4700)\n  - base_model.model.model.layers.6.self_attn.q_proj: r=16 竊 4 (Score: 0.2722)\n  - base_model.model.model.layers.6.self_attn.k_proj: r=16 竊 4 (Score: 0.2724)\n  - base_model.model.model.layers.6.self_attn.v_proj: r=16 竊 4 (Score: 0.2221)\n  - base_model.model.model.layers.6.self_attn.o_proj: r=16 竊 4 (Score: 0.2649)\n  - base_model.model.model.layers.7.self_attn.q_proj: r=16 竊 4 (Score: 0.3289)\n  - base_model.model.model.layers.7.self_attn.k_proj: r=16 竊 4 (Score: 0.2347)\n  - base_model.model.model.layers.7.self_attn.v_proj: r=16 竊 4 (Score: 0.4039)\n  - base_model.model.model.layers.7.self_attn.o_proj: r=16 竊 4 (Score: 0.3411)\n  - base_model.model.model.layers.8.self_attn.q_proj: r=16 竊 3 (Score: 0.0540)\n  - base_model.model.model.layers.8.self_attn.k_proj: r=16 竊 4 (Score: 0.3513)\n  - base_model.model.model.layers.8.self_attn.v_proj: r=16 竊 5 (Score: 0.4816)\n  - base_model.model.model.layers.8.self_attn.o_proj: r=16 竊 4 (Score: 0.3135)\n  - base_model.model.model.layers.9.self_attn.q_proj: r=16 竊 4 (Score: 0.3651)\n  - base_model.model.model.layers.9.self_attn.k_proj: r=16 竊 4 (Score: 0.3417)\n  - base_model.model.model.layers.9.self_attn.v_proj: r=16 竊 4 (Score: 0.3995)\n  - base_model.model.model.layers.9.self_attn.o_proj: r=16 竊 5 (Score: 0.4349)\n  - base_model.model.model.layers.10.self_attn.q_proj: r=16 竊 4 (Score: 0.3474)\n  - base_model.model.model.layers.10.self_attn.k_proj: r=16 竊 3 (Score: 0.1442)\n  - base_model.model.model.layers.10.self_attn.v_proj: r=16 竊 4 (Score: 0.2463)\n  - base_model.model.model.layers.10.self_attn.o_proj: r=16 竊 3 (Score: 0.1480)\n  - base_model.model.model.layers.11.self_attn.q_proj: r=16 竊 3 (Score: 0.1826)\n  - base_model.model.model.layers.11.self_attn.k_proj: r=16 竊 6 (Score: 0.6170)\n  - base_model.model.model.layers.11.self_attn.v_proj: r=16 竊 3 (Score: 0.1396)\n  - base_model.model.model.layers.11.self_attn.o_proj: r=16 竊 4 (Score: 0.3857)\n  - base_model.model.model.layers.12.self_attn.q_proj: r=16 竊 3 (Score: 0.1853)\n  - base_model.model.model.layers.12.self_attn.k_proj: r=16 竊 4 (Score: 0.3644)\n  - base_model.model.model.layers.12.self_attn.v_proj: r=16 竊 9 (Score: 1.0000)\n  - base_model.model.model.layers.12.self_attn.o_proj: r=16 竊 3 (Score: 0.1320)\n  - base_model.model.model.layers.13.self_attn.q_proj: r=16 竊 4 (Score: 0.2159)\n  - base_model.model.model.layers.13.self_attn.k_proj: r=16 竊 4 (Score: 0.2904)\n  - base_model.model.model.layers.13.self_attn.v_proj: r=16 竊 3 (Score: 0.1230)\n  - base_model.model.model.layers.13.self_attn.o_proj: r=16 竊 4 (Score: 0.2990)\n  - base_model.model.model.layers.14.self_attn.q_proj: r=16 竊 3 (Score: 0.1873)\n  - base_model.model.model.layers.14.self_attn.k_proj: r=16 竊 3 (Score: 0.1819)\n  - base_model.model.model.layers.14.self_attn.v_proj: r=16 竊 5 (Score: 0.4150)\n  - base_model.model.model.layers.14.self_attn.o_proj: r=16 竊 4 (Score: 0.2853)\n  - base_model.model.model.layers.15.self_attn.q_proj: r=16 竊 4 (Score: 0.2212)\n  - base_model.model.model.layers.15.self_attn.k_proj: r=16 竊 4 (Score: 0.3516)\n  - base_model.model.model.layers.15.self_attn.v_proj: r=16 竊 3 (Score: 0.0113)\n  - base_model.model.model.layers.15.self_attn.o_proj: r=16 竊 3 (Score: 0.1214)\n  - base_model.model.model.layers.16.self_attn.q_proj: r=16 竊 5 (Score: 0.4214)\n  - base_model.model.model.layers.16.self_attn.k_proj: r=16 竊 5 (Score: 0.4124)\n  - base_model.model.model.layers.16.self_attn.v_proj: r=16 竊 5 (Score: 0.4895)\n  - base_model.model.model.layers.16.self_attn.o_proj: r=16 竊 3 (Score: 0.2015)\n  - base_model.model.model.layers.17.self_attn.q_proj: r=16 竊 4 (Score: 0.3443)\n  - base_model.model.model.layers.17.self_attn.k_proj: r=16 竊 4 (Score: 0.2577)\n  - base_model.model.model.layers.17.self_attn.v_proj: r=16 竊 3 (Score: 0.1985)\n  - base_model.model.model.layers.17.self_attn.o_proj: r=16 竊 4 (Score: 0.2690)\n  - base_model.model.model.layers.18.self_attn.q_proj: r=16 竊 4 (Score: 0.2381)\n  - base_model.model.model.layers.18.self_attn.k_proj: r=16 竊 4 (Score: 0.3038)\n  - base_model.model.model.layers.18.self_attn.v_proj: r=16 竊 4 (Score: 0.2394)\n  - base_model.model.model.layers.18.self_attn.o_proj: r=16 竊 5 (Score: 0.4122)\n  - base_model.model.model.layers.19.self_attn.q_proj: r=16 竊 4 (Score: 0.3253)\n  - base_model.model.model.layers.19.self_attn.k_proj: r=16 竊 4 (Score: 0.2860)\n  - base_model.model.model.layers.19.self_attn.v_proj: r=16 竊 5 (Score: 0.5083)\n  - base_model.model.model.layers.19.self_attn.o_proj: r=16 竊 3 (Score: 0.1216)\n  - base_model.model.model.layers.20.self_attn.q_proj: r=16 竊 5 (Score: 0.4211)\n  - base_model.model.model.layers.20.self_attn.k_proj: r=16 竊 5 (Score: 0.4817)\n  - base_model.model.model.layers.20.self_attn.v_proj: r=16 竊 3 (Score: 0.1551)\n  - base_model.model.model.layers.20.self_attn.o_proj: r=16 竊 4 (Score: 0.2455)\n  - base_model.model.model.layers.21.self_attn.q_proj: r=16 竊 4 (Score: 0.3189)\n  - base_model.model.model.layers.21.self_attn.k_proj: r=16 竊 5 (Score: 0.4835)\n  - base_model.model.model.layers.21.self_attn.v_proj: r=16 竊 4 (Score: 0.3165)\n  - base_model.model.model.layers.21.self_attn.o_proj: r=16 竊 4 (Score: 0.3040)\n  - base_model.model.model.layers.22.self_attn.q_proj: r=16 竊 4 (Score: 0.2988)\n  - base_model.model.model.layers.22.self_attn.k_proj: r=16 竊 3 (Score: 0.0101)\n  - base_model.model.model.layers.22.self_attn.v_proj: r=16 竊 4 (Score: 0.3068)\n  - base_model.model.model.layers.22.self_attn.o_proj: r=16 竊 5 (Score: 0.4092)\n  - base_model.model.model.layers.23.self_attn.q_proj: r=16 竊 4 (Score: 0.2491)\n  - base_model.model.model.layers.23.self_attn.k_proj: r=16 竊 4 (Score: 0.3242)\n  - base_model.model.model.layers.23.self_attn.v_proj: r=16 竊 4 (Score: 0.3878)\n  - base_model.model.model.layers.23.self_attn.o_proj: r=16 竊 4 (Score: 0.3052)\n  - base_model.model.model.layers.24.self_attn.q_proj: r=16 竊 4 (Score: 0.3458)\n  - base_model.model.model.layers.24.self_attn.k_proj: r=16 竊 4 (Score: 0.2990)\n  - base_model.model.model.layers.24.self_attn.v_proj: r=16 竊 5 (Score: 0.4817)\n  - base_model.model.model.layers.24.self_attn.o_proj: r=16 竊 4 (Score: 0.2196)\n  - base_model.model.model.layers.25.self_attn.q_proj: r=16 竊 4 (Score: 0.3155)\n  - base_model.model.model.layers.25.self_attn.k_proj: r=16 竊 5 (Score: 0.4644)\n  - base_model.model.model.layers.25.self_attn.v_proj: r=16 竊 4 (Score: 0.3326)\n  - base_model.model.model.layers.25.self_attn.o_proj: r=16 竊 5 (Score: 0.4561)\n  - base_model.model.model.layers.26.self_attn.q_proj: r=16 竊 4 (Score: 0.3324)\n  - base_model.model.model.layers.26.self_attn.k_proj: r=16 竊 3 (Score: 0.0843)\n  - base_model.model.model.layers.26.self_attn.v_proj: r=16 竊 3 (Score: 0.1255)\n  - base_model.model.model.layers.26.self_attn.o_proj: r=16 竊 4 (Score: 0.3952)\n  - base_model.model.model.layers.27.self_attn.q_proj: r=16 竊 4 (Score: 0.2948)\n  - base_model.model.model.layers.27.self_attn.k_proj: r=16 竊 7 (Score: 0.7664)\n  - base_model.model.model.layers.27.self_attn.v_proj: r=16 竊 3 (Score: 0.0710)\n  - base_model.model.model.layers.27.self_attn.o_proj: r=16 竊 4 (Score: 0.2449)\n  - base_model.model.model.layers.28.self_attn.q_proj: r=16 竊 4 (Score: 0.2399)\n  - base_model.model.model.layers.28.self_attn.k_proj: r=16 竊 4 (Score: 0.2316)\n  - base_model.model.model.layers.28.self_attn.v_proj: r=16 竊 3 (Score: 0.0205)\n  - base_model.model.model.layers.28.self_attn.o_proj: r=16 竊 4 (Score: 0.2571)\n  - base_model.model.model.layers.29.self_attn.q_proj: r=16 竊 4 (Score: 0.2562)\n  - base_model.model.model.layers.29.self_attn.k_proj: r=16 竊 3 (Score: 0.1800)\n  - base_model.model.model.layers.29.self_attn.v_proj: r=16 竊 5 (Score: 0.5086)\n  - base_model.model.model.layers.29.self_attn.o_proj: r=16 竊 3 (Score: 0.0850)\n  - base_model.model.model.layers.30.self_attn.q_proj: r=16 竊 4 (Score: 0.3084)\n  - base_model.model.model.layers.30.self_attn.k_proj: r=16 竊 3 (Score: 0.1419)\n  - base_model.model.model.layers.30.self_attn.v_proj: r=16 竊 4 (Score: 0.2605)\n  - base_model.model.model.layers.30.self_attn.o_proj: r=16 竊 3 (Score: 0.1585)\n  - base_model.model.model.layers.31.self_attn.q_proj: r=16 竊 5 (Score: 0.4227)\n  - base_model.model.model.layers.31.self_attn.k_proj: r=16 竊 6 (Score: 0.5810)\n  - base_model.model.model.layers.31.self_attn.v_proj: r=16 竊 4 (Score: 0.3722)\n  - base_model.model.model.layers.31.self_attn.o_proj: r=16 竊 4 (Score: 0.2876)\n笨 AdaptiveLoRA: Rank setup for Epoch 1 complete.\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [39/39 06:28, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Perplexity</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>5.676900</td>\n      <td>7.535729</td>\n      <td>1873.809692</td>\n      <td>0.069391</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.862500</td>\n      <td>7.535729</td>\n      <td>1873.809692</td>\n      <td>0.069391</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>7.248600</td>\n      <td>7.535729</td>\n      <td>1873.809692</td>\n      <td>0.069391</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"沒 Epoch 1: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n\n\n--- AdaptiveLoRA: Preparing ranks for Epoch 2 ---\nComputing BI importance scores (pre-training)...\nAllocating new ranks based on BI scores...\nApplying new ranks to LoRA modules for this epoch...\n  - base_model.model.model.layers.0.self_attn.q_proj: r=4 (Unchanged, Score: 0.3409)\n  - base_model.model.model.layers.0.self_attn.k_proj: r=4 (Unchanged, Score: 0.3332)\n  - base_model.model.model.layers.0.self_attn.v_proj: r=5 (Unchanged, Score: 0.4457)\n  - base_model.model.model.layers.0.self_attn.o_proj: r=4 (Unchanged, Score: 0.2834)\n  - base_model.model.model.layers.1.self_attn.q_proj: r=4 (Unchanged, Score: 0.2290)\n  - base_model.model.model.layers.1.self_attn.k_proj: r=3 (Unchanged, Score: 0.0138)\n  - base_model.model.model.layers.1.self_attn.v_proj: r=3 (Unchanged, Score: 0.1664)\n  - base_model.model.model.layers.1.self_attn.o_proj: r=4 (Unchanged, Score: 0.2309)\n  - base_model.model.model.layers.2.self_attn.q_proj: r=4 (Unchanged, Score: 0.3366)\n  - base_model.model.model.layers.2.self_attn.k_proj: r=5 (Unchanged, Score: 0.4551)\n  - base_model.model.model.layers.2.self_attn.v_proj: r=3 (Unchanged, Score: 0.1450)\n  - base_model.model.model.layers.2.self_attn.o_proj: r=4 (Unchanged, Score: 0.3197)\n  - base_model.model.model.layers.3.self_attn.q_proj: r=4 (Unchanged, Score: 0.3458)\n  - base_model.model.model.layers.3.self_attn.k_proj: r=3 (Unchanged, Score: 0.1457)\n  - base_model.model.model.layers.3.self_attn.v_proj: r=3 (Unchanged, Score: 0.1881)\n  - base_model.model.model.layers.3.self_attn.o_proj: r=4 (Unchanged, Score: 0.3227)\n  - base_model.model.model.layers.4.self_attn.q_proj: r=4 (Unchanged, Score: 0.2139)\n  - base_model.model.model.layers.4.self_attn.k_proj: r=4 (Unchanged, Score: 0.3109)\n  - base_model.model.model.layers.4.self_attn.v_proj: r=3 (Unchanged, Score: 0.1075)\n  - base_model.model.model.layers.4.self_attn.o_proj: r=4 (Unchanged, Score: 0.2285)\n  - base_model.model.model.layers.5.self_attn.q_proj: r=4 (Unchanged, Score: 0.2873)\n  - base_model.model.model.layers.5.self_attn.k_proj: r=3 (Unchanged, Score: 0.0000)\n  - base_model.model.model.layers.5.self_attn.v_proj: r=4 (Unchanged, Score: 0.4014)\n  - base_model.model.model.layers.5.self_attn.o_proj: r=5 (Unchanged, Score: 0.4700)\n  - base_model.model.model.layers.6.self_attn.q_proj: r=4 (Unchanged, Score: 0.2722)\n  - base_model.model.model.layers.6.self_attn.k_proj: r=4 (Unchanged, Score: 0.2724)\n  - base_model.model.model.layers.6.self_attn.v_proj: r=4 (Unchanged, Score: 0.2221)\n  - base_model.model.model.layers.6.self_attn.o_proj: r=4 (Unchanged, Score: 0.2649)\n  - base_model.model.model.layers.7.self_attn.q_proj: r=4 (Unchanged, Score: 0.3289)\n  - base_model.model.model.layers.7.self_attn.k_proj: r=4 (Unchanged, Score: 0.2347)\n  - base_model.model.model.layers.7.self_attn.v_proj: r=4 (Unchanged, Score: 0.4039)\n  - base_model.model.model.layers.7.self_attn.o_proj: r=4 (Unchanged, Score: 0.3411)\n  - base_model.model.model.layers.8.self_attn.q_proj: r=3 (Unchanged, Score: 0.0540)\n  - base_model.model.model.layers.8.self_attn.k_proj: r=4 (Unchanged, Score: 0.3513)\n  - base_model.model.model.layers.8.self_attn.v_proj: r=5 (Unchanged, Score: 0.4816)\n  - base_model.model.model.layers.8.self_attn.o_proj: r=4 (Unchanged, Score: 0.3135)\n  - base_model.model.model.layers.9.self_attn.q_proj: r=4 (Unchanged, Score: 0.3651)\n  - base_model.model.model.layers.9.self_attn.k_proj: r=4 (Unchanged, Score: 0.3417)\n  - base_model.model.model.layers.9.self_attn.v_proj: r=4 (Unchanged, Score: 0.3995)\n  - base_model.model.model.layers.9.self_attn.o_proj: r=5 (Unchanged, Score: 0.4349)\n  - base_model.model.model.layers.10.self_attn.q_proj: r=4 (Unchanged, Score: 0.3474)\n  - base_model.model.model.layers.10.self_attn.k_proj: r=3 (Unchanged, Score: 0.1442)\n  - base_model.model.model.layers.10.self_attn.v_proj: r=4 (Unchanged, Score: 0.2463)\n  - base_model.model.model.layers.10.self_attn.o_proj: r=3 (Unchanged, Score: 0.1480)\n  - base_model.model.model.layers.11.self_attn.q_proj: r=3 (Unchanged, Score: 0.1826)\n  - base_model.model.model.layers.11.self_attn.k_proj: r=6 (Unchanged, Score: 0.6170)\n  - base_model.model.model.layers.11.self_attn.v_proj: r=3 (Unchanged, Score: 0.1396)\n  - base_model.model.model.layers.11.self_attn.o_proj: r=4 (Unchanged, Score: 0.3857)\n  - base_model.model.model.layers.12.self_attn.q_proj: r=3 (Unchanged, Score: 0.1853)\n  - base_model.model.model.layers.12.self_attn.k_proj: r=4 (Unchanged, Score: 0.3644)\n  - base_model.model.model.layers.12.self_attn.v_proj: r=9 (Unchanged, Score: 1.0000)\n  - base_model.model.model.layers.12.self_attn.o_proj: r=3 (Unchanged, Score: 0.1320)\n  - base_model.model.model.layers.13.self_attn.q_proj: r=4 (Unchanged, Score: 0.2159)\n  - base_model.model.model.layers.13.self_attn.k_proj: r=4 (Unchanged, Score: 0.2904)\n  - base_model.model.model.layers.13.self_attn.v_proj: r=3 (Unchanged, Score: 0.1230)\n  - base_model.model.model.layers.13.self_attn.o_proj: r=4 (Unchanged, Score: 0.2990)\n  - base_model.model.model.layers.14.self_attn.q_proj: r=3 (Unchanged, Score: 0.1873)\n  - base_model.model.model.layers.14.self_attn.k_proj: r=3 (Unchanged, Score: 0.1819)\n  - base_model.model.model.layers.14.self_attn.v_proj: r=5 (Unchanged, Score: 0.4150)\n  - base_model.model.model.layers.14.self_attn.o_proj: r=4 (Unchanged, Score: 0.2853)\n  - base_model.model.model.layers.15.self_attn.q_proj: r=4 (Unchanged, Score: 0.2212)\n  - base_model.model.model.layers.15.self_attn.k_proj: r=4 (Unchanged, Score: 0.3516)\n  - base_model.model.model.layers.15.self_attn.v_proj: r=3 (Unchanged, Score: 0.0113)\n  - base_model.model.model.layers.15.self_attn.o_proj: r=3 (Unchanged, Score: 0.1214)\n  - base_model.model.model.layers.16.self_attn.q_proj: r=5 (Unchanged, Score: 0.4214)\n  - base_model.model.model.layers.16.self_attn.k_proj: r=5 (Unchanged, Score: 0.4124)\n  - base_model.model.model.layers.16.self_attn.v_proj: r=5 (Unchanged, Score: 0.4895)\n  - base_model.model.model.layers.16.self_attn.o_proj: r=3 (Unchanged, Score: 0.2015)\n  - base_model.model.model.layers.17.self_attn.q_proj: r=4 (Unchanged, Score: 0.3443)\n  - base_model.model.model.layers.17.self_attn.k_proj: r=4 (Unchanged, Score: 0.2577)\n  - base_model.model.model.layers.17.self_attn.v_proj: r=3 (Unchanged, Score: 0.1985)\n  - base_model.model.model.layers.17.self_attn.o_proj: r=4 (Unchanged, Score: 0.2690)\n  - base_model.model.model.layers.18.self_attn.q_proj: r=4 (Unchanged, Score: 0.2381)\n  - base_model.model.model.layers.18.self_attn.k_proj: r=4 (Unchanged, Score: 0.3038)\n  - base_model.model.model.layers.18.self_attn.v_proj: r=4 (Unchanged, Score: 0.2394)\n  - base_model.model.model.layers.18.self_attn.o_proj: r=5 (Unchanged, Score: 0.4122)\n  - base_model.model.model.layers.19.self_attn.q_proj: r=4 (Unchanged, Score: 0.3253)\n  - base_model.model.model.layers.19.self_attn.k_proj: r=4 (Unchanged, Score: 0.2860)\n  - base_model.model.model.layers.19.self_attn.v_proj: r=5 (Unchanged, Score: 0.5083)\n  - base_model.model.model.layers.19.self_attn.o_proj: r=3 (Unchanged, Score: 0.1216)\n  - base_model.model.model.layers.20.self_attn.q_proj: r=5 (Unchanged, Score: 0.4211)\n  - base_model.model.model.layers.20.self_attn.k_proj: r=5 (Unchanged, Score: 0.4817)\n  - base_model.model.model.layers.20.self_attn.v_proj: r=3 (Unchanged, Score: 0.1551)\n  - base_model.model.model.layers.20.self_attn.o_proj: r=4 (Unchanged, Score: 0.2455)\n  - base_model.model.model.layers.21.self_attn.q_proj: r=4 (Unchanged, Score: 0.3189)\n  - base_model.model.model.layers.21.self_attn.k_proj: r=5 (Unchanged, Score: 0.4835)\n  - base_model.model.model.layers.21.self_attn.v_proj: r=4 (Unchanged, Score: 0.3165)\n  - base_model.model.model.layers.21.self_attn.o_proj: r=4 (Unchanged, Score: 0.3040)\n  - base_model.model.model.layers.22.self_attn.q_proj: r=4 (Unchanged, Score: 0.2988)\n  - base_model.model.model.layers.22.self_attn.k_proj: r=3 (Unchanged, Score: 0.0101)\n  - base_model.model.model.layers.22.self_attn.v_proj: r=4 (Unchanged, Score: 0.3068)\n  - base_model.model.model.layers.22.self_attn.o_proj: r=5 (Unchanged, Score: 0.4092)\n  - base_model.model.model.layers.23.self_attn.q_proj: r=4 (Unchanged, Score: 0.2491)\n  - base_model.model.model.layers.23.self_attn.k_proj: r=4 (Unchanged, Score: 0.3242)\n  - base_model.model.model.layers.23.self_attn.v_proj: r=4 (Unchanged, Score: 0.3878)\n  - base_model.model.model.layers.23.self_attn.o_proj: r=4 (Unchanged, Score: 0.3052)\n  - base_model.model.model.layers.24.self_attn.q_proj: r=4 (Unchanged, Score: 0.3458)\n  - base_model.model.model.layers.24.self_attn.k_proj: r=4 (Unchanged, Score: 0.2990)\n  - base_model.model.model.layers.24.self_attn.v_proj: r=5 (Unchanged, Score: 0.4817)\n  - base_model.model.model.layers.24.self_attn.o_proj: r=4 (Unchanged, Score: 0.2196)\n  - base_model.model.model.layers.25.self_attn.q_proj: r=4 (Unchanged, Score: 0.3155)\n  - base_model.model.model.layers.25.self_attn.k_proj: r=5 (Unchanged, Score: 0.4644)\n  - base_model.model.model.layers.25.self_attn.v_proj: r=4 (Unchanged, Score: 0.3326)\n  - base_model.model.model.layers.25.self_attn.o_proj: r=5 (Unchanged, Score: 0.4561)\n  - base_model.model.model.layers.26.self_attn.q_proj: r=4 (Unchanged, Score: 0.3324)\n  - base_model.model.model.layers.26.self_attn.k_proj: r=3 (Unchanged, Score: 0.0843)\n  - base_model.model.model.layers.26.self_attn.v_proj: r=3 (Unchanged, Score: 0.1255)\n  - base_model.model.model.layers.26.self_attn.o_proj: r=4 (Unchanged, Score: 0.3952)\n  - base_model.model.model.layers.27.self_attn.q_proj: r=4 (Unchanged, Score: 0.2948)\n  - base_model.model.model.layers.27.self_attn.k_proj: r=7 (Unchanged, Score: 0.7664)\n  - base_model.model.model.layers.27.self_attn.v_proj: r=3 (Unchanged, Score: 0.0710)\n  - base_model.model.model.layers.27.self_attn.o_proj: r=4 (Unchanged, Score: 0.2449)\n  - base_model.model.model.layers.28.self_attn.q_proj: r=4 (Unchanged, Score: 0.2399)\n  - base_model.model.model.layers.28.self_attn.k_proj: r=4 (Unchanged, Score: 0.2316)\n  - base_model.model.model.layers.28.self_attn.v_proj: r=3 (Unchanged, Score: 0.0205)\n  - base_model.model.model.layers.28.self_attn.o_proj: r=4 (Unchanged, Score: 0.2571)\n  - base_model.model.model.layers.29.self_attn.q_proj: r=4 (Unchanged, Score: 0.2562)\n  - base_model.model.model.layers.29.self_attn.k_proj: r=3 (Unchanged, Score: 0.1800)\n  - base_model.model.model.layers.29.self_attn.v_proj: r=5 (Unchanged, Score: 0.5086)\n  - base_model.model.model.layers.29.self_attn.o_proj: r=3 (Unchanged, Score: 0.0850)\n  - base_model.model.model.layers.30.self_attn.q_proj: r=4 (Unchanged, Score: 0.3084)\n  - base_model.model.model.layers.30.self_attn.k_proj: r=3 (Unchanged, Score: 0.1419)\n  - base_model.model.model.layers.30.self_attn.v_proj: r=4 (Unchanged, Score: 0.2605)\n  - base_model.model.model.layers.30.self_attn.o_proj: r=3 (Unchanged, Score: 0.1585)\n  - base_model.model.model.layers.31.self_attn.q_proj: r=5 (Unchanged, Score: 0.4227)\n  - base_model.model.model.layers.31.self_attn.k_proj: r=6 (Unchanged, Score: 0.5810)\n  - base_model.model.model.layers.31.self_attn.v_proj: r=4 (Unchanged, Score: 0.3722)\n  - base_model.model.model.layers.31.self_attn.o_proj: r=4 (Unchanged, Score: 0.2876)\n笨 AdaptiveLoRA: Rank setup for Epoch 2 complete.\n\n沒 Epoch 2: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n\n\n--- AdaptiveLoRA: Preparing ranks for Epoch 3 ---\nComputing BI importance scores (pre-training)...\nAllocating new ranks based on BI scores...\nApplying new ranks to LoRA modules for this epoch...\n  - base_model.model.model.layers.0.self_attn.q_proj: r=4 (Unchanged, Score: 0.3409)\n  - base_model.model.model.layers.0.self_attn.k_proj: r=4 (Unchanged, Score: 0.3332)\n  - base_model.model.model.layers.0.self_attn.v_proj: r=5 (Unchanged, Score: 0.4457)\n  - base_model.model.model.layers.0.self_attn.o_proj: r=4 (Unchanged, Score: 0.2834)\n  - base_model.model.model.layers.1.self_attn.q_proj: r=4 (Unchanged, Score: 0.2290)\n  - base_model.model.model.layers.1.self_attn.k_proj: r=3 (Unchanged, Score: 0.0138)\n  - base_model.model.model.layers.1.self_attn.v_proj: r=3 (Unchanged, Score: 0.1664)\n  - base_model.model.model.layers.1.self_attn.o_proj: r=4 (Unchanged, Score: 0.2309)\n  - base_model.model.model.layers.2.self_attn.q_proj: r=4 (Unchanged, Score: 0.3366)\n  - base_model.model.model.layers.2.self_attn.k_proj: r=5 (Unchanged, Score: 0.4551)\n  - base_model.model.model.layers.2.self_attn.v_proj: r=3 (Unchanged, Score: 0.1450)\n  - base_model.model.model.layers.2.self_attn.o_proj: r=4 (Unchanged, Score: 0.3197)\n  - base_model.model.model.layers.3.self_attn.q_proj: r=4 (Unchanged, Score: 0.3458)\n  - base_model.model.model.layers.3.self_attn.k_proj: r=3 (Unchanged, Score: 0.1457)\n  - base_model.model.model.layers.3.self_attn.v_proj: r=3 (Unchanged, Score: 0.1881)\n  - base_model.model.model.layers.3.self_attn.o_proj: r=4 (Unchanged, Score: 0.3227)\n  - base_model.model.model.layers.4.self_attn.q_proj: r=4 (Unchanged, Score: 0.2139)\n  - base_model.model.model.layers.4.self_attn.k_proj: r=4 (Unchanged, Score: 0.3109)\n  - base_model.model.model.layers.4.self_attn.v_proj: r=3 (Unchanged, Score: 0.1075)\n  - base_model.model.model.layers.4.self_attn.o_proj: r=4 (Unchanged, Score: 0.2285)\n  - base_model.model.model.layers.5.self_attn.q_proj: r=4 (Unchanged, Score: 0.2873)\n  - base_model.model.model.layers.5.self_attn.k_proj: r=3 (Unchanged, Score: 0.0000)\n  - base_model.model.model.layers.5.self_attn.v_proj: r=4 (Unchanged, Score: 0.4014)\n  - base_model.model.model.layers.5.self_attn.o_proj: r=5 (Unchanged, Score: 0.4700)\n  - base_model.model.model.layers.6.self_attn.q_proj: r=4 (Unchanged, Score: 0.2722)\n  - base_model.model.model.layers.6.self_attn.k_proj: r=4 (Unchanged, Score: 0.2724)\n  - base_model.model.model.layers.6.self_attn.v_proj: r=4 (Unchanged, Score: 0.2221)\n  - base_model.model.model.layers.6.self_attn.o_proj: r=4 (Unchanged, Score: 0.2649)\n  - base_model.model.model.layers.7.self_attn.q_proj: r=4 (Unchanged, Score: 0.3289)\n  - base_model.model.model.layers.7.self_attn.k_proj: r=4 (Unchanged, Score: 0.2347)\n  - base_model.model.model.layers.7.self_attn.v_proj: r=4 (Unchanged, Score: 0.4039)\n  - base_model.model.model.layers.7.self_attn.o_proj: r=4 (Unchanged, Score: 0.3411)\n  - base_model.model.model.layers.8.self_attn.q_proj: r=3 (Unchanged, Score: 0.0540)\n  - base_model.model.model.layers.8.self_attn.k_proj: r=4 (Unchanged, Score: 0.3513)\n  - base_model.model.model.layers.8.self_attn.v_proj: r=5 (Unchanged, Score: 0.4816)\n  - base_model.model.model.layers.8.self_attn.o_proj: r=4 (Unchanged, Score: 0.3135)\n  - base_model.model.model.layers.9.self_attn.q_proj: r=4 (Unchanged, Score: 0.3651)\n  - base_model.model.model.layers.9.self_attn.k_proj: r=4 (Unchanged, Score: 0.3417)\n  - base_model.model.model.layers.9.self_attn.v_proj: r=4 (Unchanged, Score: 0.3995)\n  - base_model.model.model.layers.9.self_attn.o_proj: r=5 (Unchanged, Score: 0.4349)\n  - base_model.model.model.layers.10.self_attn.q_proj: r=4 (Unchanged, Score: 0.3474)\n  - base_model.model.model.layers.10.self_attn.k_proj: r=3 (Unchanged, Score: 0.1442)\n  - base_model.model.model.layers.10.self_attn.v_proj: r=4 (Unchanged, Score: 0.2463)\n  - base_model.model.model.layers.10.self_attn.o_proj: r=3 (Unchanged, Score: 0.1480)\n  - base_model.model.model.layers.11.self_attn.q_proj: r=3 (Unchanged, Score: 0.1826)\n  - base_model.model.model.layers.11.self_attn.k_proj: r=6 (Unchanged, Score: 0.6170)\n  - base_model.model.model.layers.11.self_attn.v_proj: r=3 (Unchanged, Score: 0.1396)\n  - base_model.model.model.layers.11.self_attn.o_proj: r=4 (Unchanged, Score: 0.3857)\n  - base_model.model.model.layers.12.self_attn.q_proj: r=3 (Unchanged, Score: 0.1853)\n  - base_model.model.model.layers.12.self_attn.k_proj: r=4 (Unchanged, Score: 0.3644)\n  - base_model.model.model.layers.12.self_attn.v_proj: r=9 (Unchanged, Score: 1.0000)\n  - base_model.model.model.layers.12.self_attn.o_proj: r=3 (Unchanged, Score: 0.1320)\n  - base_model.model.model.layers.13.self_attn.q_proj: r=4 (Unchanged, Score: 0.2159)\n  - base_model.model.model.layers.13.self_attn.k_proj: r=4 (Unchanged, Score: 0.2904)\n  - base_model.model.model.layers.13.self_attn.v_proj: r=3 (Unchanged, Score: 0.1230)\n  - base_model.model.model.layers.13.self_attn.o_proj: r=4 (Unchanged, Score: 0.2990)\n  - base_model.model.model.layers.14.self_attn.q_proj: r=3 (Unchanged, Score: 0.1873)\n  - base_model.model.model.layers.14.self_attn.k_proj: r=3 (Unchanged, Score: 0.1819)\n  - base_model.model.model.layers.14.self_attn.v_proj: r=5 (Unchanged, Score: 0.4150)\n  - base_model.model.model.layers.14.self_attn.o_proj: r=4 (Unchanged, Score: 0.2853)\n  - base_model.model.model.layers.15.self_attn.q_proj: r=4 (Unchanged, Score: 0.2212)\n  - base_model.model.model.layers.15.self_attn.k_proj: r=4 (Unchanged, Score: 0.3516)\n  - base_model.model.model.layers.15.self_attn.v_proj: r=3 (Unchanged, Score: 0.0113)\n  - base_model.model.model.layers.15.self_attn.o_proj: r=3 (Unchanged, Score: 0.1214)\n  - base_model.model.model.layers.16.self_attn.q_proj: r=5 (Unchanged, Score: 0.4214)\n  - base_model.model.model.layers.16.self_attn.k_proj: r=5 (Unchanged, Score: 0.4124)\n  - base_model.model.model.layers.16.self_attn.v_proj: r=5 (Unchanged, Score: 0.4895)\n  - base_model.model.model.layers.16.self_attn.o_proj: r=3 (Unchanged, Score: 0.2015)\n  - base_model.model.model.layers.17.self_attn.q_proj: r=4 (Unchanged, Score: 0.3443)\n  - base_model.model.model.layers.17.self_attn.k_proj: r=4 (Unchanged, Score: 0.2577)\n  - base_model.model.model.layers.17.self_attn.v_proj: r=3 (Unchanged, Score: 0.1985)\n  - base_model.model.model.layers.17.self_attn.o_proj: r=4 (Unchanged, Score: 0.2690)\n  - base_model.model.model.layers.18.self_attn.q_proj: r=4 (Unchanged, Score: 0.2381)\n  - base_model.model.model.layers.18.self_attn.k_proj: r=4 (Unchanged, Score: 0.3038)\n  - base_model.model.model.layers.18.self_attn.v_proj: r=4 (Unchanged, Score: 0.2394)\n  - base_model.model.model.layers.18.self_attn.o_proj: r=5 (Unchanged, Score: 0.4122)\n  - base_model.model.model.layers.19.self_attn.q_proj: r=4 (Unchanged, Score: 0.3253)\n  - base_model.model.model.layers.19.self_attn.k_proj: r=4 (Unchanged, Score: 0.2860)\n  - base_model.model.model.layers.19.self_attn.v_proj: r=5 (Unchanged, Score: 0.5083)\n  - base_model.model.model.layers.19.self_attn.o_proj: r=3 (Unchanged, Score: 0.1216)\n  - base_model.model.model.layers.20.self_attn.q_proj: r=5 (Unchanged, Score: 0.4211)\n  - base_model.model.model.layers.20.self_attn.k_proj: r=5 (Unchanged, Score: 0.4817)\n  - base_model.model.model.layers.20.self_attn.v_proj: r=3 (Unchanged, Score: 0.1551)\n  - base_model.model.model.layers.20.self_attn.o_proj: r=4 (Unchanged, Score: 0.2455)\n  - base_model.model.model.layers.21.self_attn.q_proj: r=4 (Unchanged, Score: 0.3189)\n  - base_model.model.model.layers.21.self_attn.k_proj: r=5 (Unchanged, Score: 0.4835)\n  - base_model.model.model.layers.21.self_attn.v_proj: r=4 (Unchanged, Score: 0.3165)\n  - base_model.model.model.layers.21.self_attn.o_proj: r=4 (Unchanged, Score: 0.3040)\n  - base_model.model.model.layers.22.self_attn.q_proj: r=4 (Unchanged, Score: 0.2988)\n  - base_model.model.model.layers.22.self_attn.k_proj: r=3 (Unchanged, Score: 0.0101)\n  - base_model.model.model.layers.22.self_attn.v_proj: r=4 (Unchanged, Score: 0.3068)\n  - base_model.model.model.layers.22.self_attn.o_proj: r=5 (Unchanged, Score: 0.4092)\n  - base_model.model.model.layers.23.self_attn.q_proj: r=4 (Unchanged, Score: 0.2491)\n  - base_model.model.model.layers.23.self_attn.k_proj: r=4 (Unchanged, Score: 0.3242)\n  - base_model.model.model.layers.23.self_attn.v_proj: r=4 (Unchanged, Score: 0.3878)\n  - base_model.model.model.layers.23.self_attn.o_proj: r=4 (Unchanged, Score: 0.3052)\n  - base_model.model.model.layers.24.self_attn.q_proj: r=4 (Unchanged, Score: 0.3458)\n  - base_model.model.model.layers.24.self_attn.k_proj: r=4 (Unchanged, Score: 0.2990)\n  - base_model.model.model.layers.24.self_attn.v_proj: r=5 (Unchanged, Score: 0.4817)\n  - base_model.model.model.layers.24.self_attn.o_proj: r=4 (Unchanged, Score: 0.2196)\n  - base_model.model.model.layers.25.self_attn.q_proj: r=4 (Unchanged, Score: 0.3155)\n  - base_model.model.model.layers.25.self_attn.k_proj: r=5 (Unchanged, Score: 0.4644)\n  - base_model.model.model.layers.25.self_attn.v_proj: r=4 (Unchanged, Score: 0.3326)\n  - base_model.model.model.layers.25.self_attn.o_proj: r=5 (Unchanged, Score: 0.4561)\n  - base_model.model.model.layers.26.self_attn.q_proj: r=4 (Unchanged, Score: 0.3324)\n  - base_model.model.model.layers.26.self_attn.k_proj: r=3 (Unchanged, Score: 0.0843)\n  - base_model.model.model.layers.26.self_attn.v_proj: r=3 (Unchanged, Score: 0.1255)\n  - base_model.model.model.layers.26.self_attn.o_proj: r=4 (Unchanged, Score: 0.3952)\n  - base_model.model.model.layers.27.self_attn.q_proj: r=4 (Unchanged, Score: 0.2948)\n  - base_model.model.model.layers.27.self_attn.k_proj: r=7 (Unchanged, Score: 0.7664)\n  - base_model.model.model.layers.27.self_attn.v_proj: r=3 (Unchanged, Score: 0.0710)\n  - base_model.model.model.layers.27.self_attn.o_proj: r=4 (Unchanged, Score: 0.2449)\n  - base_model.model.model.layers.28.self_attn.q_proj: r=4 (Unchanged, Score: 0.2399)\n  - base_model.model.model.layers.28.self_attn.k_proj: r=4 (Unchanged, Score: 0.2316)\n  - base_model.model.model.layers.28.self_attn.v_proj: r=3 (Unchanged, Score: 0.0205)\n  - base_model.model.model.layers.28.self_attn.o_proj: r=4 (Unchanged, Score: 0.2571)\n  - base_model.model.model.layers.29.self_attn.q_proj: r=4 (Unchanged, Score: 0.2562)\n  - base_model.model.model.layers.29.self_attn.k_proj: r=3 (Unchanged, Score: 0.1800)\n  - base_model.model.model.layers.29.self_attn.v_proj: r=5 (Unchanged, Score: 0.5086)\n  - base_model.model.model.layers.29.self_attn.o_proj: r=3 (Unchanged, Score: 0.0850)\n  - base_model.model.model.layers.30.self_attn.q_proj: r=4 (Unchanged, Score: 0.3084)\n  - base_model.model.model.layers.30.self_attn.k_proj: r=3 (Unchanged, Score: 0.1419)\n  - base_model.model.model.layers.30.self_attn.v_proj: r=4 (Unchanged, Score: 0.2605)\n  - base_model.model.model.layers.30.self_attn.o_proj: r=3 (Unchanged, Score: 0.1585)\n  - base_model.model.model.layers.31.self_attn.q_proj: r=5 (Unchanged, Score: 0.4227)\n  - base_model.model.model.layers.31.self_attn.k_proj: r=6 (Unchanged, Score: 0.5810)\n  - base_model.model.model.layers.31.self_attn.v_proj: r=4 (Unchanged, Score: 0.3722)\n  - base_model.model.model.layers.31.self_attn.o_proj: r=4 (Unchanged, Score: 0.2876)\n笨 AdaptiveLoRA: Rank setup for Epoch 3 complete.\n\n沒 Epoch 3: Rank allocations logged to ./logs/adaptive_lora_epoch_logs.csv\n\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=39, training_loss=7.232385733188727, metrics={'train_runtime': 406.4299, 'train_samples_per_second': 0.369, 'train_steps_per_second': 0.096, 'total_flos': 819577316966400.0, 'train_loss': 7.232385733188727, 'epoch': 3.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(\"\\n沐 Evaluating on Validation Data...\")\nmetrics = trainer.evaluate()\nprint(\"Validation Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:44:18.524415Z","iopub.execute_input":"2025-11-06T19:44:18.524971Z","iopub.status.idle":"2025-11-06T19:44:38.378906Z","shell.execute_reply.started":"2025-11-06T19:44:18.524947Z","shell.execute_reply":"2025-11-06T19:44:38.378033Z"}},"outputs":[{"name":"stdout","text":"\n沐 Evaluating on Validation Data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:25]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Validation Metrics: {'eval_loss': 7.535728931427002, 'eval_perplexity': 1873.8096923828125, 'eval_bleu': 0.06939069736815669, 'eval_runtime': 19.8458, 'eval_samples_per_second': 1.008, 'eval_steps_per_second': 0.252, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(\"\\n洫ｪ Evaluating on Test Data...\")\ntest_metrics = trainer.evaluate(test_dataset)\nprint(\"Test Metrics:\", test_metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:44:38.379998Z","iopub.execute_input":"2025-11-06T19:44:38.380257Z","iopub.status.idle":"2025-11-06T19:44:48.209239Z","shell.execute_reply.started":"2025-11-06T19:44:38.380237Z","shell.execute_reply":"2025-11-06T19:44:48.208499Z"}},"outputs":[{"name":"stdout","text":"\n洫ｪ Evaluating on Test Data...\nTest Metrics: {'eval_loss': 8.660954475402832, 'eval_perplexity': 5773.04248046875, 'eval_bleu': 0.05768250542290915, 'eval_runtime': 9.8202, 'eval_samples_per_second': 1.018, 'eval_steps_per_second': 0.305, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"prompt = \"The history of artificial intelligence began\"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\nwith torch.no_grad():\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=40,\n        do_sample=True,\n        temperature=0.8,\n        top_p=0.9\n    )\n\nprint(\"\\n笨ｨ Example Prediction:\")\nprint(tokenizer.decode(outputs[0], skip_special_tokens=True))\n\nprint(\"\\n笨 Training complete. Check logs/adaptive_lora_epoch_logs.csv for rank evolution.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:44:48.209914Z","iopub.execute_input":"2025-11-06T19:44:48.210094Z","iopub.status.idle":"2025-11-06T19:44:52.379462Z","shell.execute_reply.started":"2025-11-06T19:44:48.210080Z","shell.execute_reply":"2025-11-06T19:44:52.378747Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n笨ｨ Example Prediction:\nThe history of artificial intelligence began in the early 20th century, when scientists first began to explore the possibility of building machines that could think and reason. Since then, the field has seen many advances, including the development of\n\n笨 Training complete. Check logs/adaptive_lora_epoch_logs.csv for rank evolution.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}